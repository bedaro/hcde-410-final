{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Climate Data Fetch\n",
    "\n",
    "This notebook downloads climate data from NOAA's FTP server for all stations listed in the stations file, and for the specified years.\n",
    "\n",
    "## Parameters\n",
    "\n",
    "**stations_file**: the name of the CSV listing all the Meteoroligcal stations to look for. The first column is\n",
    "the index of station IDs from NOAA's Integrated Surface Database (ISD). See https://www.ncdc.noaa.gov/isd/data-access\n",
    "\n",
    "**fetch_host**: the domain name of the FTP server where the files are.\n",
    "\n",
    "**fetch_dir**: the pattern of the directory structure containing the files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "stations_file = \"Salish Sea met stations.csv\"\n",
    "fetch_host = \"ftp.ncei.noaa.gov\"\n",
    "fetch_dir = \"/pub/data/noaa/isd-lite/{year}/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ftplib is included with Python 3. Pandas is required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from ftplib import FTP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the stations CSV into a Pandas dataframe, indexed by the ISD number (column 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ISD number</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>727935-24234</th>\n",
       "      <td>Boeing Field</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>727935-99999</th>\n",
       "      <td>Boeing Field King Co</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>727976-24217</th>\n",
       "      <td>Bellingham Airport</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>720749-24255</th>\n",
       "      <td>Whidbey Airport</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>727923-94225</th>\n",
       "      <td>Hoquiam Airport</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Name\n",
       "ISD number                        \n",
       "727935-24234          Boeing Field\n",
       "727935-99999  Boeing Field King Co\n",
       "727976-24217    Bellingham Airport\n",
       "720749-24255       Whidbey Airport\n",
       "727923-94225       Hoquiam Airport"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stations = pd.read_csv(stations_file, index_col=0)\n",
    "stations.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Connect to the FTP server.\n",
    "\n",
    "Note that the server has an inactivity timeout, so you may need to re-run this cell to reconnect if you get\n",
    "a timeout message later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'230-****** WARNING ** WARNING ** WARNING ** WARNING ** WARNING ** ** WARNING ** WARNING ** WARNING ******\\n ** You are accessing a U.S. Government information system, which includes:                         **\\n ** 1) This computer, 2)This computer network, 3) All computers connected to this network, and      **\\n ** 4) All devices and storage media attached to this network or to a computer on this network.     **\\n ** You understand and consent to the following:                                                    **\\n ** you may access this information system for authorized use only; you have no reasonable          **\\n ** expectation of privacy regarding any communication of data transiting or stored on this         **\\n ** information system; at any time and for any lawful Government purpose, the Government may       **\\n ** monitor, intercept, and search and seize any communication or data transiting or stored on      **\\n ** this information system; and any communications or data transiting or stored on this            **\\n ** information system may be disclosed or used for any lawful Government purpose.                  **\\n ****** WARNING ** WARNING ** WARNING ** WARNING ** WARNING ** ** WARNING ** WARNING ** WARNING ******\\n230 Anonymous'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ftp = FTP(fetch_host)\n",
    "ftp.login()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main code. Each file is a single station (named by station ID) for a single year. So iterate over the years,\n",
    "and download all the available station files. The files which are available are determined by retrieving an FTP file listing, running the function file_callback on each one to check if it is in the stations Dataframe. If it is, add it to the list `avail_files`, which then gets iterated on to download the files one by one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_download(ftp, stations, years, save_dir):\n",
    "    avail_files = []\n",
    "    def file_callback(line):\n",
    "        filename = \" \".join(line.split()).split(\" \")[-1]\n",
    "        stationid = filename[0:12]\n",
    "        if stationid in stations.index:\n",
    "            avail_files.append(filename)\n",
    "\n",
    "    for year in years:\n",
    "        avail_files = []\n",
    "        ftp.cwd(fetch_dir.format(year=year))\n",
    "        ftp.retrlines('LIST', callback = file_callback)\n",
    "        for f in avail_files:\n",
    "            with open(save_dir + f, 'wb') as fp:\n",
    "                ftp.retrbinary(\"RETR {0}\".format(f), fp.write)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download all the climate data for all stations in the DF since 1980.\n",
    "\n",
    "This cell can take a while to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "do_download(ftp, stations, range(1980, 2021), \"data/all-since-1980/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When the download is finished, all the files will be in the save_dir. Files are gzipped.\n",
    "Processing of the files into a single comprehensive dataset is done in ProcessClimateData"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Long Run Fetch\n",
    "\n",
    "Download all the data for the six stations identified in the long run stations file, as far back as we can reasonably go."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "longrun_stations = pd.read_csv('met_stations_longrun.csv', index_col=0)\n",
    "do_download(ftp, longrun_stations, range(1960, 2021), \"data/long-run-1960/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
